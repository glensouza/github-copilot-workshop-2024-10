# The Data Flow Behind GitHub Copilot

## Inbound Data Flow

In the previous module, we spent some time learning about LLMs, foundation models, and how GitHub Copilot works using OpenAI's Codex model and how that specific LLM is trained by billions of lines of source code from publicly available sources. Having a basic understanding of these LLMs and how the model treats data by taking context as an input, transform it, and then provide an output can help you better interact with GitHub Copilot and provide insight into what happens when you ask GitHub Copilot to perform an action. But this model that get a Copilot uses is just part of the flow that occurs when you interact with it. This data flow of GitHub Copilot includes the OpenAI model that does a lot of the heavy lifting or the magic behind the scenes. But there are several steps that occur before the prompt or request that gets to the model and several steps that occur once the model has adapted the input request before the user sees the output response. This data flow can be separated into two main parts, the inbound data flow and the outbound data flow. So, let's take a minute and look at each one of these data flows and see what is actually happening under the hood when we interact with GitHub Copilot. Now again, for the scope of this course, we'll stick to a high‑level overview without diving too deep into any particular section, but it will give you a good understanding of the general flow that occurs. So, with that introduction, let's start with the inbound data flow. The data flow starts with your code editor or your IDE. Because GitHub Copilot is based on the use of a plugin within your code editor, GitHub Copilot is scoped to your local environment within that code editor. It doesn't look at your Git repositories, your other file systems, or any open browsers that you may have opened. However, once you initiate a prompt or request with GitHub Copilot, if you have open files within your code editor, GitHub Copilot does look at those open files for context to better understand your code to provide you more accurate suggestions. Now we saw this happen in real time when we were building out our snake game. Once a prompt is sent from the code editor, GitHub Copilot will first look at the main open file and notice where your cursor is positioned within that file. Copilot will then pull a window of roughly 400 characters before and after your cursor. It will evaluate the code within that window and then will look at any open tabs within your code editor to see if there's anything useful that it can reference to give a better prompt suggestion. A common example of this is writing unit tests. If you're writing unit tests in one file and the file you're testing is in an adjacent tab, GitHub Copilot will evaluate the initial code in the main file around your cursor, look at the code in the adjacent tab for additional context, and then use all of that information to provide you a better prompt suggestion. Now, at this point, all of this data that is being curated together then gets bundled up and sent over to a proxy server or a proxy service. This proxy server is basically a computer that sits between your device, your code editor, and the OpenAI model. It's important to note that all of this data is encrypted before it is sent over to the proxy service. The prompt is sent over HTTPS using TLS 1.2 or 1.3, which is the same secure method if you were to make a purchase online, use VPN protocols, secure file transfers, and other common forms to secure data transfers. In short, it's secure, encrypted, and considered a highly secured cryptographic protocol for securing communication over the internet. Now, once the data is encrypted, it's sent over to this Copilot proxy server. The proxy service is run in a GitHub‑owned Azure tenant. GitHub controls this proxy service and sets the specifications on how it runs the pre and post processing of the code that goes through the proxy service. On the preprocessing side, once the prompt has been encrypted and has been received by the proxy, the proxy service will decrypt the data, keep it in RAM for processing, and filter the data for a few things. One filter that it does is perform a scrub of information that is considered personally identifiable information or PII data. This can include things like IP addresses, email addresses, or even certain GitHub URLs. Now this kind of data will be scrubbed from the prompt request before it moves on to the model. Another thing that happens in this proxy service is what's called a toxicity filter. GitHub Copilot runs through Microsoft's responsible AI toxicity filter and will remove things like hate speech, profanity, and even request to intentionally abuse the model. Anything that falls into this category will simply be removed from the request. If it finds PII data, it gets stripped out. If it finds something toxic, offensive, or abusive, Copilot just ignores it. In addition to the filtering that takes place, the proxy service also runs a code classifier based on the prompt data. So for example, is it code that the user wants back? If it is, what kind? Are the files in Java, Python, or something else? All of this information is what the proxy service is doing on the front end. Now, once this preprocessing is done, it remains in RAM and nothing is ever stored at rest. It then gets re encrypted and sent to the model. Once the data is sent to the OpenAI model specific for GitHub Copilot, the quality of suggestions you receive may depend on the volume and diversity of the training data for that language. You can think of this model as performing applied statistics instead of just copying and pasting code as a prompt suggestion. The model is taking everything that was passed from the proxy service and essentially breaking it down into small bits of information called tokens. So for example, if you were to take a sentence, pretend that each word is a token and the model is mapping each token's proximity to every other token that it sees and using that data to provide the response. Let's look at an example using Java. If the prompt starts with public, most of the time the next word is going to be class. Now, statistically, if you have a public class, most of the time the next thing is going to be a variable name, defining that class. Using another Java example, if the prompt reads public static, most of the time you know that the next thing is going to be void main because that is the typical language for a Java main method and is what you would expect to see as the return prompt suggestion. So in general, the model is looking at the prompt that was provided and then evaluating the statistically most likely prompt response back to the user based on the series of tokens that it was given. As this model receives more training, the responses become more accurate and the model can better predict your desired outcome. So that's essentially what this model is doing. It gets this encrypted prompt from the proxy service that's gone through this preprocessing scrub, decrypting it, and running its token analysis before returning the prompt response back to the proxy service. That is the inbound data flow.

## Outbound Data Flow

Now that we have the inbound data flow covered, we're now looking at the outbound data flow where everything goes back in the other direction. Once the model is done generating the list of suggestions, it returns those suggestions to the same proxy service as before. Within this same proxy service, the suggestions generated from the model are put through the same filters as the inbound data. The suggestions go through the same toxicity filter to remove things like hate speech or profanity from the suggestions. They also go through an identity filter for PII data. So again, that's any information like email addresses, IP addresses, or any hardcoded credentials. They also go through a code quality filter that checks for common security vulnerabilities within the generated suggestions, as well as the obvious incorrect suggestions. Another filter the data is passed through is an intent classifier. This filter makes sure that the generated suggestions are for a user actually writing code. And another filter that is optional when setting up GitHub Copilot is the duplicate detection filter. Now this filter looks at any generated suggestion that exceeds about 150 characters that matches any open source code that is publicly available on GitHub. If you have this filter enabled, GitHub Copilot will not provide that suggestion if it finds a public match. And lastly, any suggestions that survive this rigorous journey are encrypted and sent back over to the code editor for the user to see. So in summary, the data flow starts with the developer's code editor. Copilot looks for context to see what the developer is working on. It does this by looking at a few lines before and after the cursor, as well as any adjacent files open in the editor to better understand the intent of the developer. Once Copilot assembles enough context, the context is packaged into a prompt that flows to the proxy server. This is basically a computer that sits in between the user's device and the AI model. At this proxy server, the prompt runs through a toxicity filter, as well as an identifier filter. And once the prompt clears those filters, it goes to the AI model where suggestions are then generated. The suggestions then start the return back to the proxy server where they then go through a series of filters, a toxicity filter, identifier filter, a code quality filter, and intent classifier filter, and, if enabled, a duplicate detection filter. At this point, any suggestions that survive are shown to the developer in their code editor. And with the generated suggestions, if you're using GitHub Copilot Business or Enterprise, the prompt is discarded and becomes part of garbage collection, and GitHub doesn't store it. If you're using GitHub Copilot individual, you can choose whether or not you want to share your prompts with GitHub Copilot. So when garbage collection comes along, once the suggestions array is transmitted to the developer's code editor, the suggestions then get deleted during garbage collection and are deleted from memory. So all of this is happening like a constant stream of data, and it's occurring in less than a blink of an eye. A prompt gets initiated, it goes through the model and suggestions are generated. Then suggestions come back and are sent to the user's code editor and are then deleted. Now that we have a better understanding of what's happening when we interact with GitHub Copilot and the data flow that occurs under the hood, with this knowledge in mind, let's see a basic and quick example of this happening in real time by using the different options of GitHub Copilot. Back in our code editor, I have a blank Python file. So let's add a basic function to generate the Fibonacci sequence up to a given number. Let's first interact with GitHub Copilot by converting a comment to code, something we've done a lot. Let's say write a function that generates a Fibonacci sequence of n numbers and prints it out. Based on that comment, Copilot gives me a basic function called fib, and it takes in one argument called n. Okay, cool. Now that I have a basic function defined, I can use GitHub Copilot to suggest my next code. And in this case, it's code to populate the inside of my new function. Copilot provides what it thinks is the best option based on the context. But I can navigate through the different options to find a different solution if presented. Now with GitHub Copilot, when the prompt is sent to the model and suggestions are generated, Copilot, on average, generates up to 10% potential solutions for you to choose from. You can open up the GitHub Copilot window to see these alternative solutions that were generated. You can scan through the options and accept the solution that best fits your use case. This is a great way to see the other options if you're looking to explore alternative solutions. So, let's accept a solution that looks best and then add it to our file. Now I can press Enter to another line in the file, and Copilot understands that after the function is defined, I probably will want to provide an argument so that it will print the argument number in the Fibonacci sequence. And it provides an example of 10. I can then run this code. And looking at my terminal, I can see the printed output to the correct Fibonacci sequence up to the argument number as provided, which was 10. Okay, pretty cool. And to top it off, I can use GitHub Copilot Chat to then highlight the code and open up my Copilot Chat window and ask Copilot to explain this code to me. And Copilot will provide a detailed description of the code I have and what it is exactly doing. And looking through this information, I can get a better understanding of what exactly is happening. And if I want to alter this code, I can use Copilot Chat to make suggestions or I can return to my file and make more comments to initiate a prompt, or I can start coding and Copilot will help provide suggestions as I go.
